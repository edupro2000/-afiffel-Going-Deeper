{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "devoted-password",
   "metadata": {},
   "source": [
    "#### 준비물 (터미널 셋팅)\n",
    "- mkdir -p ~/aiffel/s2s_translation\n",
    "- sudo apt -qq -y install fonts-nanum #글꼴 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "retired-clarity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "완료!\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "%config InlineBackend.figure_format = 'retina'\n",
    " \n",
    "import matplotlib.font_manager as fm\n",
    "fontpath = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'\n",
    "font = fm.FontProperties(fname=fontpath, size=9)\n",
    "plt.rc('font', family='NanumBarunGothic') \n",
    "mpl.font_manager._rebuild()\n",
    "\n",
    "print(\"완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "economic-affiliation",
   "metadata": {},
   "source": [
    "### 1. 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continued-street",
   "metadata": {},
   "source": [
    "#### 1) 데이터 준비하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "champion-fourth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "import io\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "frequent-event",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_zip = tf.keras.utils.get_file(\n",
    "    'spa-eng.zip',\n",
    "    origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip',\n",
    "    extract=True)\n",
    "\n",
    "path_to_file = os.path.dirname(path_to_zip)+\"/spa-eng/spa.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "second-satin",
   "metadata": {},
   "source": [
    "- tf.keras.utils.get_file(): URL로부터 데이터를 다운받고, 압축된 형식일 경우 해제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "unable-poison",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Size: 118964\n",
      "Example:\n",
      ">> Go.\tVe.\n",
      ">> Wait.\tEsperen.\n",
      ">> Hug me.\tAbrázame.\n",
      ">> No way!\t¡Ni cagando!\n",
      ">> Call me.\tLlamame.\n"
     ]
    }
   ],
   "source": [
    "# 다운 받은 데이터 형태 확인\n",
    "\n",
    "with open(path_to_file, \"r\") as f:\n",
    "    raw = f.read().splitlines()\n",
    "\n",
    "print(\"Data Size:\", len(raw))\n",
    "print(\"Example:\")\n",
    "\n",
    "for sen in raw[0:100][::20]: print(\">>\", sen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exposed-enzyme",
   "metadata": {},
   "source": [
    "#### 2) 데이터 전처리: 정제하기\n",
    "- 데이터는 \\t 기호를 기준으로 영어와 스페인어가 병렬 쌍을 이루고 있다.  \\t 기호를 매개변수로 split() 함수를 호출하면 손쉽게 소스 문장과 타겟 문장을 분리가능\n",
    "- Decoder는 첫 입력으로 사용할 시작 토큰과 문장생성 종료를 알리는 끝 토큰이 반드시 필요하기 때문에 전처리 과정에서 문장의 시작 문자 <start>, 종료 문자 <end> 를 붙여주게된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "demanding-excess",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝~\n"
     ]
    }
   ],
   "source": [
    "# 특수문자 제외\n",
    "\n",
    "def preprocess_sentence(sentence, s_token=False, e_token=False):\n",
    "    sentence = sentence.lower().strip()\n",
    "\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "    sentence = re.sub(r\"[^a-zA-Z?.!,]+\", \" \", sentence)\n",
    "\n",
    "    sentence = sentence.strip()\n",
    "\n",
    "    if s_token:\n",
    "        sentence = '<start> ' + sentence\n",
    "\n",
    "    if e_token:\n",
    "        sentence += ' <end>'\n",
    "    \n",
    "    return sentence\n",
    "\n",
    "print(\"슝~\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "beginning-chester",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English: go away !\n",
      "Spanish: <start> salga de aqu ! <end>\n"
     ]
    }
   ],
   "source": [
    "# 상위 3만개 데이터 학습\n",
    "enc_corpus = []\n",
    "dec_corpus = []\n",
    "\n",
    "num_examples = 30000\n",
    "\n",
    "for pair in raw[:num_examples]:\n",
    "    eng, spa = pair.split(\"\\t\")\n",
    "\n",
    "    enc_corpus.append(preprocess_sentence(eng))\n",
    "    dec_corpus.append(preprocess_sentence(spa, s_token=True, e_token=True))\n",
    "\n",
    "print(\"English:\", enc_corpus[100])   # go away !\n",
    "print(\"Spanish:\", dec_corpus[100])   # <start> salga de aqu ! <end>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlike-kitchen",
   "metadata": {},
   "source": [
    "#### 데이터 전처리: 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "collect-rebound",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정제된 텍스트를 아래처럼 토큰화 하고 텐서로 변환 (훈련데이터 80%, 검증데이터 20% 분리)\n",
    "\n",
    "def tokenize(corpus):\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "\n",
    "    tensor = tokenizer.texts_to_sequences(corpus)\n",
    "\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
    "\n",
    "    return tensor, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cheap-nicholas",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Vocab Size: 4931\n",
      "Spanish Vocab Size: 8893\n"
     ]
    }
   ],
   "source": [
    "# 토큰화하기\n",
    "enc_tensor, enc_tokenizer = tokenize(enc_corpus)\n",
    "dec_tensor, dec_tokenizer = tokenize(dec_corpus)\n",
    "\n",
    "# 훈련 데이터와 검증 데이터로 분리하기\n",
    "enc_train, enc_val, dec_train, dec_val = \\\n",
    "train_test_split(enc_tensor, dec_tensor, test_size=0.2) #split() 함수: 손쉽게 소스 문장과 타겟 문장을 분리\n",
    "\n",
    "print(\"English Vocab Size:\", len(enc_tokenizer.index_word))\n",
    "print(\"Spanish Vocab Size:\", len(dec_tokenizer.index_word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prompt-holocaust",
   "metadata": {},
   "source": [
    "<mark>[1. 데이터 전처리 영역 학습 재정리]</mark>\n",
    "- 1) 데이터 준비 - tf.keras.utils.get_file(): URL로부터 데이터를 다운받고, 압축된 형식일 경우 해제\n",
    "- 2) 데이터 전처리: 정제하기\n",
    "    - \\t 기호를 매개변수로 split() 함수를 호출하면 손쉽게 소스 문장과 타겟 문장을 분리가능\n",
    "    - Decoder는 첫 입력으로 사용할 시작 토큰과 문장생성 종료를 알리는 끝 토큰이 반드시 필요\n",
    "- 3) 데이터 토큰화\n",
    "   - 토큰화후 텐서로 변환, 훈련데이터, 훈련 데이터와 검증 데이터로 분리하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "auburn-worse",
   "metadata": {},
   "source": [
    "### 2. 모델설계\n",
    "- Encoder는 모든 Time-Step의 Hidden State(=기억)를 출력\n",
    "- Decoder는 Encoder의 출력과 Decoder의 t-1 Step의 Hidden State로 Attention을 취하여 t Step의 Hidden State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "designing-motivation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝~\n"
     ]
    }
   ],
   "source": [
    "# Attention은 Bahdanau을 사용 *7번 노드 참고\n",
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.w_dec = tf.keras.layers.Dense(units)\n",
    "        self.w_enc = tf.keras.layers.Dense(units)\n",
    "        self.w_com = tf.keras.layers.Dense(1)\n",
    "    \n",
    "    def call(self, h_enc, h_dec):\n",
    "        # h_enc shape: [batch x length x units]\n",
    "        # h_dec shape: [batch x units]\n",
    "\n",
    "        h_enc = self.w_enc(h_enc)   \n",
    "        h_dec = tf.expand_dims(h_dec, 1)\n",
    "        h_dec = self.w_dec(h_dec)  #인코더의 실제 히든디코더를 한번 더 확인하도록\n",
    "\n",
    "        score = self.w_com(tf.nn.tanh(h_dec + h_enc))  #탄젠트\n",
    "        \n",
    "        attn = tf.nn.softmax(score, axis=1) #소프트맥스\n",
    "\n",
    "        context_vec = attn * h_enc   #컨텍스벡터 어텐션가중치 *컨벡스트백터(히든디코더)\n",
    "        context_vec = tf.reduce_sum(context_vec, axis=1) # 가중치 다 더해주기\n",
    "\n",
    "        return context_vec, attn\n",
    "\n",
    "print(\"슝~\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "vulnerable-audit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder 클래스와 설계 \n",
    "\n",
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(enc_units,\n",
    "                                       return_sequences=True)\n",
    "        \n",
    "    def call(self, x):\n",
    "        out = self.embedding(x)\n",
    "        out = self.gru(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "private-profit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder 클래스를 설계\n",
    "    \n",
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(dec_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True)\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "    def call(self, x, h_dec, enc_out):\n",
    "        context_vec, attn = self.attention(enc_out, h_dec)\n",
    "\n",
    "        out = self.embedding(x)\n",
    "        out = tf.concat([tf.expand_dims(context_vec, 1), out], axis=-1)\n",
    "        \n",
    "        out, h_dec = self.gru(out)\n",
    "        out = tf.reshape(out, (-1, out.shape[2]))\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out, h_dec, attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "demographic-mounting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder Output: (64, 30, 1024)\n",
      "Decoder Output: (64, 8894)\n",
      "Decoder Hidden State: (64, 1024)\n",
      "Attention: (64, 30, 1)\n"
     ]
    }
   ],
   "source": [
    "# 코드를 실행하세요.\n",
    "\n",
    "BATCH_SIZE     = 64\n",
    "SRC_VOCAB_SIZE = len(enc_tokenizer.index_word) + 1\n",
    "TGT_VOCAB_SIZE = len(dec_tokenizer.index_word) + 1\n",
    "\n",
    "units         = 1024\n",
    "embedding_dim = 512\n",
    "\n",
    "encoder = Encoder(SRC_VOCAB_SIZE, embedding_dim, units)\n",
    "decoder = Decoder(TGT_VOCAB_SIZE, embedding_dim, units)\n",
    "\n",
    "# sample input\n",
    "sequence_len = 30\n",
    "\n",
    "sample_enc = tf.random.uniform((BATCH_SIZE, sequence_len))\n",
    "sample_output = encoder(sample_enc)\n",
    "\n",
    "print ('Encoder Output:', sample_output.shape)\n",
    "\n",
    "sample_state = tf.random.uniform((BATCH_SIZE, units))\n",
    "\n",
    "sample_logits, h_dec, attn = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
    "                                     sample_state, sample_output)\n",
    "\n",
    "print ('Decoder Output:', sample_logits.shape)\n",
    "print ('Decoder Hidden State:', h_dec.shape)\n",
    "print ('Attention:', attn.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smart-superior",
   "metadata": {},
   "source": [
    "[재 복습 - Bahdanau_Attention] \n",
    "- = 이름 : concat\n",
    "- 현재 타임 스텝의 디코더 Hidden State Vector $s_t$ 를 구하기 위해서 현재 타임 스텝의 Context Vector  $c_t$  및 이전 타임 스텝의 Hidden State Vector  $s_t-1$, 그리고 현재 타임 스텝의 입력으로 들어온  $y_t-1$ 이 사용되게 된다. 이 때  Context Vector $c_t$는 $s_t-1$과 인코더 Hidden State Matrix 를 이용한 Attention 메커니즘의 결과가 된다. \n",
    "\n",
    "![Bahdanau_Attention](https://user-images.githubusercontent.com/70866993/137129301-28753f44-751e-4658-8210-f9330ca0c9d0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "turkish-adapter",
   "metadata": {},
   "source": [
    "<mark> 2. 모델 설계 영역 학습 재정리</mark>\n",
    "- 1) 어텐션 선택\n",
    "- 2) Encoder 클래스와 설계 \n",
    "- 3) Decoder 클래스를 설계"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retired-morrison",
   "metadata": {},
   "source": [
    "### 3. 훈련하기\n",
    "- Encoder-Decoder 구조의 경우 입출력이 단순하지 않아 학습 과정을 직접 정의, fit()으로 학습시키지 않음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "twenty-title",
   "metadata": {},
   "source": [
    "#### Optimizer & Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "hollow-haven",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝~\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy( \n",
    "    from_logits=True, reduction='none')  \n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss = loss_object(real, pred)\n",
    "    \n",
    "    mask = tf.cast(mask, dtype=loss.dtype)\n",
    "    loss *= mask # 패딩처리, <PAD> 토큰을 찾아내어 그 부분에 대한 Loss는 구하지 않도록 하는 역할\n",
    "    \n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "print(\"슝~\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "soviet-going",
   "metadata": {},
   "source": [
    "- SparseCategoricalCrossentropy() 함수 :  모델이 출력한 확률 분포와 (One-hot이 아닌) 정수 인덱스 답안을 비교해 Cross Entropy값을 구해준다.\n",
    "- loss *= mask # 패딩처리, <PAD> 토큰을 찾아내어 그 부분에 대한 Loss는 구하지 않도록 하는 역할"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "leading-mercury",
   "metadata": {},
   "source": [
    "### 4. train_step 구현하기\n",
    "- train_step() : 학습에 필요한 것을 모두 가져가 Loss를 계산한 후 반환하는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "attended-coast",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝~\n"
     ]
    }
   ],
   "source": [
    "@tf.function  # 훈련 외적인 텐서플로우 연산을  GPU에서 동작하게 해 훈련을 가속할 수 있도록 도와wnsek.\n",
    "def train_step(src, tgt, encoder, decoder, optimizer, dec_tok):\n",
    "    bsz = src.shape[0]\n",
    "    loss = 0\n",
    "\n",
    "    with tf.GradientTape() as tape: #tf.GradientTape() : 학습하며 발생한 모든 연산을 기록하는 테이프\n",
    "        enc_out = encoder(src)\n",
    "        h_dec = enc_out[:, -1] # Encoder에 소스 문장을 전달해 컨텍스트 벡터인 enc_out 생성,(Encoder의 Final State 정의)\n",
    "        \n",
    "        dec_src = tf.expand_dims([dec_tok.word_index['<start>']] * bsz, 1) # Decoder에 입력으로 전달할 <start> 토큰 문장 생성\n",
    "\n",
    "        for t in range(1, tgt.shape[1]):\n",
    "            pred, h_dec, _ = decoder(dec_src, h_dec, enc_out) #<start> 문장과 enc_out, Hidden State를 기반으로 다음 단어(t=1)를 예측\n",
    "\n",
    "            loss += loss_function(tgt[:, t], pred)# 예측된 단어와 정답 간의 Loss를 구한 후, t=1의 정답 단어를 다음 입력으로 사용 (예측 단어 X)\n",
    "            dec_src = tf.expand_dims(tgt[:, t], 1)\n",
    "        \n",
    "    batch_loss = (loss / int(tgt.shape[1]))\n",
    "\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "    \n",
    "    return batch_loss\n",
    "\n",
    "print(\"슝~\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hindu-medium",
   "metadata": {},
   "source": [
    "### 5. 훈련 시작하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "contemporary-twist",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  1: 100%|██████████| 375/375 [04:00<00:00,  1.56it/s, Loss 1.3497]\n",
      "Epoch  2: 100%|██████████| 375/375 [03:39<00:00,  1.71it/s, Loss 0.8820]\n",
      "Epoch  3: 100%|██████████| 375/375 [03:41<00:00,  1.69it/s, Loss 0.6198]\n",
      "Epoch  4: 100%|██████████| 375/375 [03:40<00:00,  1.70it/s, Loss 0.4441]\n",
      "Epoch  5: 100%|██████████| 375/375 [03:39<00:00,  1.71it/s, Loss 0.3288]\n",
      "Epoch  6: 100%|██████████| 375/375 [03:42<00:00,  1.69it/s, Loss 0.2540]\n",
      "Epoch  7: 100%|██████████| 375/375 [03:42<00:00,  1.68it/s, Loss 0.2068]\n",
      "Epoch  8: 100%|██████████| 375/375 [03:39<00:00,  1.71it/s, Loss 0.1750]\n",
      "Epoch  9: 100%|██████████| 375/375 [02:17<00:00,  2.72it/s, Loss 0.1560]\n",
      "Epoch 10: 100%|██████████| 375/375 [01:44<00:00,  3.60it/s, Loss 0.1384]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm    # tqdm : 훈련의 진행 과정을 한눈에 볼 수 있게 해주는 라이브러리\n",
    "import random\n",
    "\n",
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "    \n",
    "    idx_list = list(range(0, enc_train.shape[0], BATCH_SIZE))  #각 배치의 시작 인덱스를 idx_list 배열에 저장\n",
    "    random.shuffle(idx_list)  #랜덤 인덱스 섞기\n",
    "    t = tqdm(idx_list)    # tqdm\n",
    "\n",
    "    for (batch, idx) in enumerate(t):\n",
    "        batch_loss = train_step(enc_train[idx:idx+BATCH_SIZE], #train_step 하습에 필요한것을 모두 가져가 Loss 계산후 반환\n",
    "                                dec_train[idx:idx+BATCH_SIZE],\n",
    "                                encoder,\n",
    "                                decoder,\n",
    "                                optimizer,\n",
    "                                dec_tokenizer)\n",
    "    \n",
    "        total_loss += batch_loss\n",
    "        \n",
    "        t.set_description_str('Epoch %2d' % (epoch + 1))    # tqdm\n",
    "        t.set_postfix_str('Loss %.4f' % (total_loss.numpy() / (batch + 1)))    # tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "specified-crazy",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  1: 100%|██████████| 375/375 [01:44<00:00,  3.58it/s, Loss 0.1269]\n",
      "Test Epoch  1: 100%|██████████| 94/94 [00:22<00:00,  4.26it/s, Test Loss 0.6937]\n",
      "Epoch  2: 100%|██████████| 375/375 [01:44<00:00,  3.58it/s, Loss 0.1215]\n",
      "Test Epoch  2: 100%|██████████| 94/94 [00:09<00:00,  9.59it/s, Test Loss 0.7086]\n",
      "Epoch  3: 100%|██████████| 375/375 [01:45<00:00,  3.57it/s, Loss 0.1136]\n",
      "Test Epoch  3: 100%|██████████| 94/94 [00:09<00:00,  9.64it/s, Test Loss 0.7125]\n",
      "Epoch  4: 100%|██████████| 375/375 [01:44<00:00,  3.58it/s, Loss 0.1045]\n",
      "Test Epoch  4: 100%|██████████| 94/94 [00:09<00:00,  9.58it/s, Test Loss 0.7278]\n",
      "Epoch  5: 100%|██████████| 375/375 [01:44<00:00,  3.60it/s, Loss 0.1020]\n",
      "Test Epoch  5: 100%|██████████| 94/94 [00:09<00:00,  9.65it/s, Test Loss 0.7313]\n",
      "Epoch  6: 100%|██████████| 375/375 [01:44<00:00,  3.58it/s, Loss 0.1005]\n",
      "Test Epoch  6: 100%|██████████| 94/94 [00:09<00:00,  9.65it/s, Test Loss 0.7455]\n",
      "Epoch  7: 100%|██████████| 375/375 [01:44<00:00,  3.59it/s, Loss 0.0972]\n",
      "Test Epoch  7: 100%|██████████| 94/94 [00:09<00:00,  9.61it/s, Test Loss 0.7464]\n",
      "Epoch  8: 100%|██████████| 375/375 [01:44<00:00,  3.59it/s, Loss 0.0909]\n",
      "Test Epoch  8: 100%|██████████| 94/94 [00:09<00:00,  9.61it/s, Test Loss 0.7431]\n",
      "Epoch  9: 100%|██████████| 375/375 [01:44<00:00,  3.59it/s, Loss 0.0889]\n",
      "Test Epoch  9: 100%|██████████| 94/94 [00:09<00:00,  9.59it/s, Test Loss 0.7651]\n",
      "Epoch 10: 100%|██████████| 375/375 [01:44<00:00,  3.58it/s, Loss 0.0861]\n",
      "Test Epoch 10: 100%|██████████| 94/94 [00:09<00:00,  9.62it/s, Test Loss 0.7664]\n"
     ]
    }
   ],
   "source": [
    "# Define eval_step() 정의하기\n",
    "\n",
    "@tf.function\n",
    "def eval_step(src, tgt, encoder, decoder, dec_tok):\n",
    "    bsz = src.shape[0]\n",
    "    loss = 0\n",
    "\n",
    "    enc_out = encoder(src)\n",
    "\n",
    "    h_dec = enc_out[:, -1]\n",
    "    \n",
    "    dec_src = tf.expand_dims([dec_tok.word_index['<start>']] * bsz, 1)\n",
    "\n",
    "    for t in range(1, tgt.shape[1]):\n",
    "        pred, h_dec, _ = decoder(dec_src, h_dec, enc_out)\n",
    "\n",
    "        loss += loss_function(tgt[:, t], pred)\n",
    "        dec_src = tf.expand_dims(tgt[:, t], 1)\n",
    "        \n",
    "    batch_loss = (loss / int(tgt.shape[1]))\n",
    "    \n",
    "    return batch_loss\n",
    "\n",
    "\n",
    "# 5. 훈련시작하기와 동일(total_loss, test_loss)\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    total_loss = 0   # total_loss\n",
    "    \n",
    "    idx_list = list(range(0, enc_train.shape[0], BATCH_SIZE))\n",
    "    random.shuffle(idx_list)\n",
    "    t = tqdm(idx_list)\n",
    "\n",
    "    for (batch, idx) in enumerate(t):\n",
    "        batch_loss = train_step(enc_train[idx:idx+BATCH_SIZE],\n",
    "                                dec_train[idx:idx+BATCH_SIZE],\n",
    "                                encoder,\n",
    "                                decoder,\n",
    "                                optimizer,\n",
    "                                dec_tokenizer)\n",
    "    \n",
    "        total_loss += batch_loss  #total_loss\n",
    "        \n",
    "        t.set_description_str('Epoch %2d' % (epoch + 1))\n",
    "        t.set_postfix_str('Loss %.4f' % (total_loss.numpy() / (batch + 1)))\n",
    "    \n",
    "    test_loss = 0  #test_loss\n",
    "    \n",
    "    idx_list = list(range(0, enc_val.shape[0], BATCH_SIZE))\n",
    "    random.shuffle(idx_list)\n",
    "    t = tqdm(idx_list)\n",
    "\n",
    "    for (test_batch, idx) in enumerate(t):\n",
    "        test_batch_loss = eval_step(enc_val[idx:idx+BATCH_SIZE],\n",
    "                                    dec_val[idx:idx+BATCH_SIZE],\n",
    "                                    encoder,\n",
    "                                    decoder,\n",
    "                                    dec_tokenizer)\n",
    "    \n",
    "        test_loss += test_batch_loss   #test_loss\n",
    "\n",
    "        t.set_description_str('Test Epoch %2d' % (epoch + 1))\n",
    "        t.set_postfix_str('Test Loss %.4f' % (test_loss.numpy() / (test_batch + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "changing-template",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:47: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:48: UserWarning: FixedFormatter should only be used together with FixedLocator\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: can i have some coffee ?\n",
      "Predicted translation: me pueden dar algo ? <end> \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 608,
       "width": 613
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 번역 성능 평가하기,  Attention Map을 시각화\n",
    "\n",
    "def evaluate(sentence, encoder, decoder):\n",
    "    attention = np.zeros((dec_train.shape[-1], enc_train.shape[-1]))\n",
    "    \n",
    "    sentence = preprocess_sentence(sentence)\n",
    "    inputs = enc_tokenizer.texts_to_sequences([sentence.split()])\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences(inputs,\n",
    "                                                           maxlen=enc_train.shape[-1],\n",
    "                                                           padding='post')\n",
    "\n",
    "    result = ''\n",
    "\n",
    "    enc_out = encoder(inputs)\n",
    "\n",
    "    dec_hidden = enc_out[:, -1]\n",
    "    dec_input = tf.expand_dims([dec_tokenizer.word_index['<start>']], 0)\n",
    "\n",
    "    for t in range(dec_train.shape[-1]):\n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
    "                                                             dec_hidden,\n",
    "                                                             enc_out)\n",
    "\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        attention[t] = attention_weights.numpy()\n",
    "\n",
    "        predicted_id = \\\n",
    "        tf.argmax(tf.math.softmax(predictions, axis=-1)[0]).numpy()\n",
    "\n",
    "        result += dec_tokenizer.index_word[predicted_id] + ' '\n",
    "\n",
    "        if dec_tokenizer.index_word[predicted_id] == '<end>':\n",
    "            return result, sentence, attention\n",
    "\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    return result, sentence, attention\n",
    "\n",
    "\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "    fontdict = {'fontsize': 14}\n",
    "\n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def translate(sentence, encoder, decoder):\n",
    "    result, sentence, attention = evaluate(sentence, encoder, decoder)\n",
    "\n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "    \n",
    "    attention = attention[:len(result.split()), :len(sentence.split())]\n",
    "    plot_attention(attention, sentence.split(), result.split(' '))\n",
    "\n",
    "\n",
    "translate(\"Can I have some coffee?\", encoder, decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protective-cause",
   "metadata": {},
   "source": [
    "## 프로젝트: 한영 번역기 만들기\n",
    "- [NLP-02] Sentence_Piece 참고"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floppy-flight",
   "metadata": {},
   "source": [
    "Step 1. 데이터 다운로드\n",
    "아래 링크에서 korean-english-park.train.tar.gz 를 다운로드받아 한영 병렬 데이터를 확보합니다.\n",
    "\n",
    "jungyeul/korean-parallel-corpora"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "creative-ground",
   "metadata": {},
   "source": [
    "Step 2. 데이터 정제\n",
    "1) set 데이터형이 중복을 허용하지 않는다는 것을 활용해 중복된 데이터를 제거하도록 합니다. 데이터의 병렬 쌍이 흐트러지지 않게 주의하세요! 중복을 제거한 데이터를 cleaned_corpus 에 저장합니다.\n",
    "\n",
    "2) 앞서 정의한 preprocessing() 함수는 한글에서는 동작하지 않습니다. 한글에 적용할 수 있는 정규식을 추가하여 함수를 재정의하세요!\n",
    "\n",
    "3) 타겟 언어인 영문엔 <start> 토큰과 <end> 토큰을 추가하고 split() 함수를 이용하여 토큰화합니다. 한글 토큰화는 KoNLPy의 mecab 클래스를 사용합니다. KoNLPy가 설치되어 있지 않다면 아래 문서를 참고해 설치해 주세요.\n",
    "\n",
    "설치하기-KoNLPy\n",
    "모든 데이터를 사용할 경우 학습에 굉장히 오랜 시간이 걸립니다. cleaned_corpus로부터 토큰의 길이가 40 이하인 데이터를 선별하여 eng_corpus와 kor_corpus를 각각 구축하세요.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "processed-transparency",
   "metadata": {},
   "source": [
    "Step 3. 데이터 토큰화\n",
    "앞서 정의한 tokenize() 함수를 사용해 데이터를 텐서로 변환하고 각각의 tokenizer를 얻으세요! 단어의 수는 실험을 통해 적당한 값을 맞춰주도록 합니다! (최소 10,000 이상!)\n",
    "\n",
    "❗ 주의: 난이도에 비해 데이터가 많지 않아 훈련 데이터와 검증 데이터를 따로 나누지는 않습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "private-exchange",
   "metadata": {},
   "source": [
    "Step 4. 모델 설계\n",
    "한국어를 영어로 잘 번역해 줄 멋진 Attention 기반 Seq2seq 모델을 설계하세요! 앞서 만든 모델에 Dropout 모듈을 추가하면 성능이 더 좋아집니다! Embedding Size와 Hidden Size는 실험을 통해 적당한 값을 맞춰 주도록 합니다!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continuous-coordination",
   "metadata": {},
   "source": [
    "Step 5. 훈련하기\n",
    "\n",
    "훈련엔 위에서 사용한 코드를 그대로 사용하되, eval_step() 부분이 없음에 유의합니다! 매 스텝 아래의 예문에 대한 번역을 생성하여 본인이 생각하기에 가장 멋지게 번역한 Case를 제출하세요! (Attention Map을 시각화해보는 것도 재밌을 거예요!) #난이도 높음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "overall-mention",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-24-211033670f94>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-24-211033670f94>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    K1) 오바마는 대통령이다.\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "## 예문 ##\n",
    "K1) 오바마는 대통령이다.\n",
    "K2) 시민들은 도시 속에 산다.\n",
    "K3) 커피는 필요 없다.\n",
    "K4) 일곱 명의 사망자가 발생했다.\n",
    "\n",
    "## 제출 ##\n",
    "E1) obama is the president . <end>\n",
    "E2) people are victims of the city . <end>\n",
    "E2) the price is not enough . <end>\n",
    "E2) seven people have died . <end>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shaped-surgeon",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cosmetic-authentication",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "useful-present",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "respective-standing",
   "metadata": {},
   "source": [
    "## 루브릭\n",
    "- 구두점, 대소문자, 띄어쓰기, 한글 형태소분석 등 번역기 모델에 요구되는 전처리가 정상적으로 진행되었다\n",
    "- seq2seq 모델 훈련 과정에서 training loss가 안정적으로 떨어지면서 학습이 진행됨이 확인되었다.\n",
    "- 테스트용 디코더 모델이 정상적으로 만들어져서, 정답과 어느 정도 유사한 영어 번역이 진행됨을 확인하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coated-nickel",
   "metadata": {},
   "outputs": [],
   "source": [
    "구두점, 대소문자, 띄어쓰기, 한글 형태소분석 등 번역기 모델에 요구되는 전처리가 정상적으로 진행되었다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustainable-hierarchy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uniform-hanging",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "destroyed-pizza",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pleasant-klein",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unsigned-january",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "damaged-beijing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foreign-infrastructure",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arabic-fortune",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olympic-miller",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "psychological-shade",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entitled-journalism",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flush-battle",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

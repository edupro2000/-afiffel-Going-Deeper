{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dress-ethics",
   "metadata": {},
   "source": [
    "# 15-2. ë‹¤ì–‘í•œ NLP Frameworkì˜ ì¶œí˜„"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reported-penalty",
   "metadata": {},
   "source": [
    "### General Framework for NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dressed-express",
   "metadata": {},
   "source": [
    "- ì´ë²ˆ ìŠ¤í…ì˜ ë‚´ìš©ì€ Top NLP Libraries to Use 2020ì— ì •ë¦¬ëœ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì‘ì„±\n",
    "\n",
    "- General Framework for NLP\n",
    "    - ì—¬ê¸°ì„œ ì†Œê°œí•  frameworkë“¤ì€ NLP ë¬¸ì œë¥¼ ê°€ì¥ ì¼ë°˜ì ìœ¼ë¡œ í•´ê²°í•  ìˆ˜ ìˆëŠ” í†µí•©ì ì¸ í”„ë ˆì„ì›Œí¬ë¥¼ ëª©í‘œë¡œ ì„¤ê³„ëœ ê²ƒë“¤ì…ë‹ˆë‹¤. \n",
    "    - ëŒ€í‘œì ìœ¼ë¡œëŠ” AllenNLP, Fairseq, Fast.aiê°€ ìˆìœ¼ë©°, Googleì˜ tensor2tensor í”„ë¡œì íŠ¸ë„ ê°™ì€ ë²”ì£¼ë¡œ ìƒê°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "- ğŸ”¶ AllenNLP\n",
    "ì œê³µì : Allen AI Institute\n",
    "Website : https://allennlp.org/\n",
    "Github : https://github.com/allenai/allennlp\n",
    "Backend : PyTorch\n",
    "\n",
    "2018ë…„ ì´ˆë°˜ì— Contextual Word Embeddingì˜ ëŒ€í‘œì ì¸ ëª¨ë¸ì¸ ELMOë¥¼ ë°œí‘œí•˜ë©´ì„œ ìœ ëª…í•´ì§„ Allen Instituteì—ì„œ ë§Œë“  NLP frameworkì…ë‹ˆë‹¤. ë‹¹ì‹œ ELMOëŠ” GLUE Benchmark Testì™€ ê°™ì´ 10ê°€ì§€ë‚˜ ë˜ëŠ” ë‹¤ì–‘í•œ íƒœìŠ¤í¬ë¡œ êµ¬ì„±ëœ ë°ì´í„°ì…‹ì„ í•˜ë‚˜ì˜ ëª¨ë¸ì„ finetuneí•˜ëŠ” ê²ƒë§Œìœ¼ë¡œë„ ê¸°ì¡´ì˜ State-of-the-art ê¸°ë¡ì„ ê²½ì‹ í•˜ëŠ” ì„±ëŠ¥ì„ ë³´ì—¬ì£¼ê³ ì í•˜ì˜€ìŠµë‹ˆë‹¤. ê·¸ë¬ê¸°ì— í•˜ë‚˜ì˜ ëª¨ë¸ë¡œ ë‹¤ì–‘í•œ íƒœìŠ¤í¬ë¥¼ ì†ì‰½ê²Œ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” ìœ ì—°í•œ í”„ë¡œì íŠ¸ë¥¼ êµ¬ì„±í•´ì•¼ í–ˆê³ , ì´ë¥¼ í™•ì¥í•˜ë©´ì„œ ìì—°ìŠ¤ëŸ½ê²Œ NLP frameworkë¡œ ë°œì „í•˜ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤. ì´í›„ AllenNLPëŠ” Glue datasetì˜ baseline í”„ë¡œì íŠ¸ Starting Baselineë¥¼ ì œê³µí•˜ê¸°ë„ í–ˆìŠµë‹ˆë‹¤.\n",
    "![15-AllenNLP](https://user-images.githubusercontent.com/70866993/141037573-7dd0e6b8-a78b-45cc-9eeb-86360620a47a.png)\n",
    "             [ì¶œì²˜ : AllenNLP Guide(https://guide.allennlp.org/building-your-model#1)]\n",
    "\n",
    "íƒœìŠ¤í¬ì™€ ëª¨ë¸ì„ ë¶„ë¦¬í•´ì„œ, í•œ ê°€ì§€ ëª¨ë¸ë¡œ ë‹¤ì–‘í•œ íƒœìŠ¤í¬ë¥¼ ì²˜ë¦¬í•˜ê±°ë‚˜ í•˜ë‚˜ì˜ íƒœìŠ¤í¬ë¥¼ ë‹¤ì–‘í•œ ëª¨ë¸ë¡œ ì²˜ë¦¬í•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ì„¤ê³„ëŠ” AllenNLPê°€ ì²˜ìŒ ì‹œë„í•œ ê²ƒì€ ë¬¼ë¡  ì•„ë‹™ë‹ˆë‹¤ë§Œ, ELMOì™€ ê°™ì€ pretrained modelì˜ ì„±ê³µì„ ë°”íƒ•ìœ¼ë¡œ NLP frameworkë¥¼ ì™„ì„±í•´ ë‚˜ê°€ë ¤ëŠ” AllenNLPì˜ ì‹œë„ëŠ” ì´í›„ ë§ì€ ì•„ì´ë””ì–´ë¥¼ ì œê³µí•˜ì˜€ìŠµë‹ˆë‹¤. AllenNLPëŠ” í˜„ì¬ëŠ” ELMO ì´ì™¸ì—ë„ BERT ë“± ë‹¤ì–‘í•œ ëª¨ë¸ì˜ í™œìš©ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.\n",
    "\n",
    "ë‹¨, AllenNLPëŠ” PyTorch ê¸°ë°˜ìœ¼ë¡œ ì„¤ê³„ë˜ì—ˆìœ¼ë©° ëª¨ë¸ì´ torch.nn.Moduleì„ ìƒì†ë°›ëŠ” êµ¬ì¡°ë¡œ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. Tensorflowë‚˜ Keras ê¸°ë°˜ìœ¼ë¡œ AllenNLPë¥¼ í™œìš©í•˜ëŠ” ê²ƒì€ ì–´ë µìŠµë‹ˆë‹¤.\n",
    "\n",
    "- ğŸ”¶ Fairseq\n",
    "ì œê³µì : Facebook AI Research\n",
    "Website : https://fairseq.readthedocs.io/en/latest\n",
    "Github : https://github.com/pytorch/fairseq\n",
    "Backend : PyTorch\n",
    "FairseqëŠ” ê¾¸ì¤€íˆ NLP ì—°êµ¬ì„±ê³¼ë¥¼ ë‚´ê³  ìˆëŠ” Facebook AI Researchì˜ NLP Frameworkì…ë‹ˆë‹¤. ë¹„ë‹¨ ìì—°ì–´ì²˜ë¦¬ì—ë§Œ êµ­í•œëœ ê²ƒì´ ì•„ë‹ˆë¼ ì´ë¦„ì—ì„œë„ ì•Œ ìˆ˜ ìˆë“¯ì´ CNN, LSTM ë“± ì „í†µì ì¸ ëª¨ë¸ë¡œë¶€í„°, ìŒì„±ì¸ì‹/í•©ì„± ë“± sequentialí•œ ë°ì´í„°ë¥¼ ë‹¤ë£¨ëŠ” ë¶„ì•¼ë¥¼ ë‘ë£¨ ë‹¤ë£¨ëŠ” ë‹¤ì–‘í•œ pretrained modelì„ í•¨ê»˜ ì œê³µí•˜ê³  ìˆìŠµë‹ˆë‹¤. ì—­ì‹œ Facebookì˜ frameworkë‹µê²Œ PyTorch ê¸°ë°˜ìœ¼ë¡œ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "- ğŸ”¶ Fast.ai\n",
    "ì œê³µì : fast.ai\n",
    "Website : http://docs.fast.ai/\n",
    "Github : https://github.com/fastai/fastai\n",
    "Backend : PyTorch\n",
    "fast.aiëŠ” ì´ë¦„ì— ê±¸ë§ê²Œ, ë¹ ë¥´ê²Œ ë°°ìš°ê³  ì‰½ê²Œ ëª¨ë¸ì„ êµ¬ì„±í•  ìˆ˜ ìˆë„ë¡ í•˜ì´ë ˆë²¨ APIì™€ Application ë¸”ë¡ê¹Œì§€ ì†ì‰½ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ë¹„ë‹¨ NLP ë¶„ì•¼ ë¿ ì•„ë‹ˆë¼ ë‹¤ì–‘í•œ ë¶„ì•¼ë¡œ í™•ì¥ ê°€ëŠ¥í•©ë‹ˆë‹¤. ì—­ì‹œ PyTorch ê¸°ë°˜ìœ¼ë¡œ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "![15-Fast](https://user-images.githubusercontent.com/70866993/141037664-0ff451be-2e96-4c30-834f-912021d835d8.png)\n",
    "                                  [ì¶œì²˜ : fast.ai (https://github.com/fastai/fastai)]\n",
    "\n",
    "- ğŸ”¶ tensor2tensor\n",
    "ì œê³µì : Google Brain\n",
    "Github : https://github.com/tensorflow/tensor2tensor (deprecated)\n",
    "New Github : https://github.com/google/trax\n",
    "Backend : Tensorflow\n",
    "Google Brainì—ì„œ 2017ë…„ì— transformer ë…¼ë¬¸ì„ ë°œí‘œí•˜ë©´ì„œ ê·¸ êµ¬í˜„ì²´ë¡œ í•¨ê»˜ ê³µìœ í–ˆë˜ í”„ë¡œì íŠ¸ê°€ ë°”ë¡œ tensor2tensorì˜€ìŠµë‹ˆë‹¤. ì´ í”„ë¡œì íŠ¸ ì—­ì‹œ 'Attention is all you need'ë¼ëŠ” ë…¼ë¬¸ì˜ ì œëª©ì²˜ëŸ¼, transformerë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ë‹¤ì–‘í•œ íƒœìŠ¤í¬ì™€ ë‹¤ì–‘í•œ ëª¨ë¸ì„ í•˜ë‚˜ì˜ frameworkì— í†µí•©í•˜ë ¤ëŠ” ì‹œë„ë¥¼ í•˜ì˜€ìŠµë‹ˆë‹¤. ì´í›„ 2019ë…„ë¶€í„° Googleì€ Tensorflow V2 ê¸°ë°˜ìœ¼ë¡œ pretrained modelì˜ ì§€ì›ì„ ê°•í™”í•œ traxë¼ëŠ” í”„ë¡œì íŠ¸ë¥¼ ìƒì„±í•˜ë©´ì„œ, 2020ë…„ë„ë¶€í„°ëŠ” tensor2tensorì˜ ê°œë°œì„ ì¤‘ë‹¨í•˜ê³  ê´€ë ¨ ê¸°ëŠ¥ì„ traxë¡œ í†µí•©ì´ê´€í•˜ì˜€ìŠµë‹ˆë‹¤.\n",
    "\n",
    "Tensorflow ê¸°ë°˜ì˜ NLP frameworkì´ ìƒëŒ€ì ìœ¼ë¡œ ë“œë¬¸ ê°€ìš´ë°, Tensorflow ê¸°ë°˜ì˜ NLP ì—°êµ¬ê°œë°œì„ ì§„í–‰í•œë‹¤ë©´ ì£¼ëª©í•´ ë³¼ ë§Œí•  ê²ƒì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stylish-functionality",
   "metadata": {},
   "source": [
    "#### Preprocessing Libraries\n",
    "- ì „í†µì ìœ¼ë¡œ ì‚¬ìš©ë˜ì—ˆë˜ NLP ë¶„ì•¼ì˜ ì „ì²˜ë¦¬ ê´€ë ¨ frameworkë“¤ì…ë‹ˆë‹¤. \n",
    "- ìœ„ì—ì„œ ì†Œê°œí•œ frameworkë“¤ì²˜ëŸ¼ ì „ì²˜ë¦¬-ëª¨ë¸ë§-íƒœìŠ¤í¬ í›ˆë ¨/í‰ê°€ë¥¼ í†µí•©ì ìœ¼ë¡œ ì„¤ê³„í•˜ì—¬ NLP íƒœìŠ¤í¬ë¥¼ ì œë„ˆëŸ´í•˜ê²Œ ìˆ˜í–‰í•˜ê²Œ ì„¤ê³„í•œ ê²ƒì´ ì•„ë‹ˆë¼ tokenization, tagging, parsing ë“± <b>íŠ¹ì • ì „ì²˜ë¦¬ ì‘ì—…ì„ ìœ„í•´ ì„¤ê³„ëœ ë¼ì´ë¸ŒëŸ¬ë¦¬ì— ê°€ê¹ìŠµë‹ˆë‹¤. </b>\n",
    "- ì—¬ê¸°ì—ëŠ” ì•„ë˜ ì˜ˆì‹œë¡œ ë“  Spacy, NLTK, TorchText ë“±ì´ ìˆìŠµë‹ˆë‹¤. í•œêµ­ì–´ì¸ ê²½ìš° KoNLPy ë¼ì´ë¸ŒëŸ¬ë¦¬ë„ ë™ì¼í•œ ì—­í• ì„ í•œë‹¤ê³  ë³¼ ìˆ˜ ìˆê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enabling-butter",
   "metadata": {},
   "source": [
    "ğŸ”¶ Spacy\n",
    "Website : https://spacy.io/\n",
    "Github : https://github.com/explosion/spaCy\n",
    "ğŸ”¶ NLTK\n",
    "Website : https://www.nltk.org/\n",
    "Github : https://github.com/nltk/nltk\n",
    "ğŸ”¶ TorchText\n",
    "Website : https://torchtext.readthedocs.io/en/latest/\n",
    "Github : https://github.com/pytorch/text\n",
    "ğŸ”¶ KoNLPy\n",
    "Website : https://konlpy.org/en/latest/\n",
    "Github : https://github.com/konlpy/konlpy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parliamentary-minority",
   "metadata": {},
   "source": [
    "#### Transformer-based Framework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "favorite-scene",
   "metadata": {},
   "source": [
    "ğŸ”¶ Huggingface transformers\n",
    "- ì œê³µì : Huggingface.co\n",
    "- Website : https://huggingface.co/transformers/\n",
    "- Github : https://github.com/huggingface/transformers\n",
    "- Backend : PyTorch and Tensorflow\n",
    "- ì—¬ê¸°ì—ëŠ” í˜„ì¬ ê°€ì¥ ì£¼ëª©ë°›ê³  ìˆëŠ” NLP Frameworkì¸ Huggingface transformersê°€ ìˆìŠµë‹ˆë‹¤. ì‚¬ì‹¤ Huggingfaceì˜ transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ ìµœê·¼ ëª¨ìŠµì€ ì´ë¯¸ ì•„ì£¼ generalí•œ NLP frameworkì˜ ëª¨ìŠµì„ ì¶©ë¶„íˆ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. \n",
    "- í•˜ì§€ë§Œ ì´ˆê¸°ì—ëŠ” BERT ë“± ë‹¤ì–‘í•œ transformer ê¸°ë°˜ì˜ pretrained modelì„ ì‚¬ìš©í•˜ê¸° ìœ„í•œ PyTorch ê¸°ë°˜ì˜ wrapper í˜•íƒœë¡œ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤. ê·¸ë˜ì„œ ì „í†µì ì¸ ëª¨ë¸ê¹Œì§€ í¬ê´„í•˜ë ¤ê³  í–ˆë˜ ì´ì „ì˜ general NLP Framework ë“¤ì— ë¹„í•´, Huggingfaceì˜ transformersëŠ” pretrained model í™œìš©ì„ ì£¼ë¡œ ì§€ì›í•˜ë©°, tokenizer ë“± ì „ì²˜ë¦¬ ë¶€ë¶„ë„ pretrained modelë“¤ì´ ì£¼ë¡œ ì‚¬ìš©í•˜ëŠ” Subword tokenizer ê¸°ë²•ì— ì§‘ì¤‘ë˜ì–´ ìˆëŠ” íŠ¹ì§•ì´ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì´í›„ ë‹¤ìŒ ìŠ¤í…ë¶€í„°ëŠ” Huggingfaceì˜ transformersì— ëŒ€í•´ ì§‘ì¤‘ì ìœ¼ë¡œ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accepting-workstation",
   "metadata": {},
   "source": [
    "#### Huggingface transformers ê°œìš”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fiscal-revolution",
   "metadata": {},
   "source": [
    "- (1) ê´‘ë²”ìœ„í•˜ê³  ì‹ ì†í•œ NLP ëª¨ë¸ ì§€ì›\n",
    "HuggingfaceëŠ” ë§ì€ ì‚¬ëŒë“¤ì´ ìµœì‹  NLP ëª¨ë¸ë“¤ì„ ë”ìš± ì†ì‰½ê²Œ ì‚¬ìš©í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ ë§Œë“¤ê¸° ì‹œì‘í–ˆë‹¤ê³  í•©ë‹ˆë‹¤. ê·¸ë˜ì„œ ê·¸ëŸ°ì§€ ìƒˆë¡œìš´ ë…¼ë¬¸ë“¤ì´ ë°œí‘œë  ë•Œë§ˆë‹¤, ë³¸ì¸ë“¤ì˜ frameworkì— í¡ìˆ˜ì‹œí‚¤ê³  ìˆìŠµë‹ˆë‹¤. ë˜í•œ, pretrained modelì„ ì œê³µí•˜ê³ , datasetê³¼ tokenizerë¥¼ ë”ìš± ì‰½ê²Œ ì´ìš©í•  ìˆ˜ ìˆë„ë¡ frameworkí™”ì‹œí‚¤ê³  ìˆëŠ” í–‰ë³´ë„ ë³´ì´ê³  ìˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ frameworkë“¤ë„ ì´ëŸ° ì‘ì—…ì„ í•˜ì§€ ì•ŠëŠ” ê²ƒì€ ì•„ë‹ˆì§€ë§Œ, Huggingfaceì˜ ì§€ì› ë²”ìœ„ê°€ ê°€ì¥ ê´‘ë²”ìœ„í•˜ê³ , ìµœì‹  ë…¼ë¬¸ì„ ì§€ì›í•˜ëŠ” ì†ë„ë„ ë¹ ë¦…ë‹ˆë‹¤.\n",
    "\n",
    "- (2) PyTorchì™€ Tensorflow ëª¨ë‘ì—ì„œ ì‚¬ìš© ê°€ëŠ¥\n",
    "transformersëŠ” ê¸°ë³¸ì ìœ¼ë¡œ PyTorchë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë§Œë“¤ì–´ì ¸ìˆìŠµë‹ˆë‹¤. ë§ì€ utilityê°€ PyTorch ìœ„ì£¼ë¡œ ì‘ì„±ì´ ë˜ì–´ìˆê¸´ í•˜ì§€ë§Œ, ìµœê·¼ì—ëŠ” Tensorflowë¡œë„ í•™ìŠµí•˜ê³  ì‚¬ìš©í•  ìˆ˜ ìˆê²Œë” ê³„ì†í•´ì„œ frameworkë¥¼ í™•ì¥í•˜ê³  ìˆëŠ” ì¤‘ì…ë‹ˆë‹¤. ì´ë ‡ë“¯ Huggingface transformersë¥¼ ë°”íƒ•ìœ¼ë¡œ Tensorflowì™€ PyTorchë¼ëŠ” Backendì˜ í•œê³„ë¥¼ ë›°ì–´ë„˜ì–´ ì–´ë–¤ í™˜ê²½ì—ë“  ì‰½ê²Œ ì ìš© ê°€ëŠ¥í•œ í‘œì¤€ frameworkì˜ ì§€ìœ„ë¥¼ ë‹¤ì ¸ê°€ê³  ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "- (3) ì˜ ì„¤ê³„ëœ framework êµ¬ì¡°\n",
    "HuggingFaceì˜ ëª©í‘œì²˜ëŸ¼ ì´ frameworkëŠ” ì‰½ê³  ë¹ ë¥´ê²Œ ì–´ë– í•œ í™˜ê²½ì—ì„œë„ NLPëª¨ë¸ì„ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ëŠì„ì—†ì´ ë³€í™”í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ê²ƒì€ ë˜í•œ ì‚¬ìš©í•˜ê¸° ì‰½ê³  ì§ê´€ì ì¼ë¿ë”ëŸ¬ ëª¨ë¸ì´ë‚˜ íƒœìŠ¤í¬, ë°ì´í„°ì…‹ì´ ë‹¬ë¼ì§€ë”ë¼ë„ ë™ì¼í•œ í˜•íƒœë¡œ ì‚¬ìš© ê°€ëŠ¥í•˜ë„ë¡ ì˜ ì¶”ìƒí™”ë˜ê³  ëª¨ë“ˆí™”ëœ API ì„¤ê³„ê°€ ìˆê¸° ë•Œë¬¸ì— ê°€ëŠ¥í•œ ê²ƒì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manufactured-tuesday",
   "metadata": {},
   "source": [
    "## 15-3. Huggingface transformers ê°œìš”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "studied-simulation",
   "metadata": {},
   "source": [
    "-  pip install transformers  #í´ë¼ìš°ë“œ ì‚¬ìš©ì ë¯¸ì„¤ì¹˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "universal-turtle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1260602ad4ac45638cd7181188ebb0a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23a29b0a91c14cffb85c0d5066b21d4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dba4e0366faf40cd95c47a223f95f1a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2c3a1b5f0b84e7c8f954d0d2e970c04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the layers of TFDistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9978193640708923}]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline('sentiment-analysis', framework='tf')\n",
    "classifier('We are very happy to include pipeline into the transformers repository.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "german-gathering",
   "metadata": {},
   "source": [
    "#### transformersëŠ” ìœ„ì™€ ê°™ì€ íë¦„ì— ë§ì¶”ì–´ ì„¤ê³„\n",
    "- 1) Taskë¥¼ ì •ì˜í•˜ê³  ê·¸ì— ë§ê²Œ datasetì„ ê°€ê³µì‹œí‚µë‹ˆë‹¤. Processors\n",
    "    - í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì „ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” Tokenizer\n",
    "- 2) ë‹¤ì–‘í•œ modelì„ ì„ íƒí•˜ê³   ì´ë¥¼ ë§Œë“­ë‹ˆë‹¤. \n",
    "    - optimizerì™€ í•™ìŠµ schedule(warm up ë“±)ì„ ê´€ë¦¬í•  ìˆ˜ ìˆëŠ” Optimization\n",
    "- 3) modelì— ë°ì´í„°ë“¤ì„ íƒœì›Œì„œ í•™ìŠµ(Trainer)ì„ ì‹œí‚¤ê³ , ì´ë¥¼ í†µí•´ ë‚˜ì˜¨ \n",
    "- 4) weightì™€ ì„¤ì •(config)ë“¤ì„ ì €ì¥í•©ë‹ˆë‹¤. ì €ì¥í•œ modelì˜ checkpointëŠ” \n",
    "     - weightì™€ tokenizer, modelì„ ì‰½ê²Œ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ìˆë„ë¡ ê°ì¢… ì„¤ì •ì„ ì €ì¥í•˜ëŠ” Config \n",
    "- 5) ë°°í¬í•˜ê±°ë‚˜, evaluationì„ í•  ë•Œ ì‚¬ìš©"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verified-hazard",
   "metadata": {},
   "source": [
    "## 15-4. Huggingface transformers (1) Model\n",
    "- ê¸°ë³¸ì ìœ¼ë¡œ ëª¨ë¸ë“¤ì€ PretrainedModel í´ë˜ìŠ¤ë¥¼ ìƒì†ë°›ê³  ìˆìŠµë‹ˆë‹¤. \n",
    "- PretrainedModel í´ë˜ìŠ¤ëŠ” í•™ìŠµëœ ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¤ê³ , ë‹¤ìš´ë¡œë“œí•˜ê³ , ì €ì¥í•˜ëŠ” ë“± ëª¨ë¸ ì „ë°˜ì— ê±¸ì³ ì ìš©ë˜ëŠ” ë©”ì†Œë“œë“¤ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. \n",
    "- ì´ëŸ° ìƒì† êµ¬ì¡°ë¥¼ ê°€ì§€ê³  ìˆê¸° ë•Œë¬¸ì—, ì‹¤ì œë¡œ ì‚¬ìš©í•  ëª¨ë¸ì´ BERTì´ê±´, GPTì´ê±´ ìƒê´€ì—†ì´ ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¤ê³  ë‹¤ìš´ë¡œë“œ/ì €ì¥í•˜ëŠ” ë“±ì˜ ì‘ì—…ì— í™œìš©í•˜ëŠ” ë©”ì†Œë“œëŠ” ë¶€ëª¨ í´ë˜ìŠ¤ì˜ ê²ƒì„ ë™ì¼í•˜ê²Œ í™œìš©í•  ìˆ˜ ìˆê²Œ ë©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expected-captain",
   "metadata": {},
   "source": [
    "### ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° ë°©ë²•1. \n",
    "- ì²« ë²ˆì§¸ë¡œëŠ” taskì— ì í•©í•œ ëª¨ë¸ì„ ì§ì ‘ ì„ íƒí•˜ì—¬ importí•˜ê³ , ë¶ˆëŸ¬ì˜¤ëŠ” ë°©ì‹ì´ ìˆìŠµë‹ˆë‹¤. ëª¨ë¸ì„ ë¡œë“œí•  ë•ŒëŠ” from_pretrainedë¼ëŠ” ë©”ì†Œë“œë¥¼ ì‚¬ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "comparable-canadian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf7413b457354b29821489364c977bb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae09057282db4317baa745d10d83b7f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/527M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForPreTraining.\n",
      "\n",
      "All the layers of TFBertForPreTraining were initialized from the model checkpoint at bert-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForPreTraining for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.models.bert.modeling_tf_bert.TFBertForPreTraining'>\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFBertForPreTraining\n",
    "model = TFBertForPreTraining.from_pretrained('bert-base-cased') # ëª¨ë¸ id bert-base-cased\n",
    "\n",
    "print(model.__class__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modular-retirement",
   "metadata": {},
   "source": [
    "### ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° ë°©ë²•2. \n",
    "- ë‘ ë²ˆì§¸ ë°©ë²•ì€, AutoModelì„ ì´ìš©í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.\n",
    "- ëª¨ë¸ì— ê´€í•œ ì •ë³´ë¥¼ ì²˜ìŒë¶€í„° ëª…ì‹œí•˜ì§€ ì•Šì•„ë„ ë˜ì–´ ì¡°ê¸ˆ ìœ ìš©í•˜ê²Œ ì‚¬ìš©í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "annoying-recruitment",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.models.bert.modeling_tf_bert.TFBertModel'>\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFAutoModel\n",
    "model = TFAutoModel.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "print(model.__class__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outdoor-ballet",
   "metadata": {},
   "source": [
    "## 15-5. Huggingface transformers (2) Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "induced-madrid",
   "metadata": {},
   "source": [
    "#### ëª¨ë¸ì— ë„£ì„ inputì„ ë§Œë“¤ì–´ ì¤„ ì°¨ë¡€\n",
    "- transformersëŠ” ë‹¤ì–‘í•œ tokenizerë¥¼ ê° ëª¨ë¸ì— ë§ì¶”ì–´ ì´ë¯¸ êµ¬ë¹„\n",
    "- tokenizer ë˜í•œ ì§ì ‘ ëª…ì‹œí•˜ì—¬ ë‚´ê°€ ì‚¬ìš©í•  ê²ƒì„ ì§€ì •í•´ ì£¼ê±°ë‚˜, AutoTokenizerë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ êµ¬ë¹„ëœ modelì— ì•Œë§ì€ tokenizerë¥¼ ìë™ìœ¼ë¡œ ë¶ˆëŸ¬ì˜¬ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.\n",
    "- ì´ë•Œ <mark>ìœ ì˜í•  ì ì€, modelì„ ì‚¬ìš©í•  ë•Œ ëª…ì‹œí–ˆë˜ ê²ƒê³¼ ë™ì¼í•œ IDë¡œ tokenizerë¥¼ ìƒì„±í•´ì•¼ í•œë‹¤ëŠ” ì ì…ë‹ˆë‹¤.</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "extensive-federal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ca519e6d53d4ac7b1812fa5d5e5443a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "engaging-guarantee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4db7ae2d1fc44e3c835402101feec277",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/436k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dirty-minutes",
   "metadata": {},
   "source": [
    "#### - BERTì˜ tokenizerì´ê¸° ë•Œë¬¸ì— ì¸ì½”ë”©ì´ ëœ input_ids ë¿ë§Œ ì•„ë‹ˆë¼, token_type_idsì™€ attention_maskê¹Œì§€ ëª¨ë‘ ìƒì„±ëœ input ê°ì²´ë¥¼ ë°›ì•„ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "small-breathing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 1188, 1110, 5960, 1111, 170, 11093, 1883, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "encoded = tokenizer(\"This is Test for aiffel\")\n",
    "print(encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "active-steel",
   "metadata": {},
   "source": [
    "#### - tokenizerëŠ” batch ë‹¨ìœ„ë¡œ inputì„ ë°›ì„ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "owned-pizza",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [[101, 8667, 146, 112, 182, 170, 1423, 5650, 102], [101, 1262, 1330, 5650, 102], [101, 1262, 1103, 1304, 1304, 1314, 1141, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1]]}\n"
     ]
    }
   ],
   "source": [
    "batch_sentences = [\"Hello I'm a single sentence\",\n",
    "                    \"And another sentence\",\n",
    "                    \"And the very very last one\"]\n",
    "\n",
    "encoded_batch = tokenizer(batch_sentences)\n",
    "print(encoded_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fancy-stewart",
   "metadata": {},
   "source": [
    "#### return_tensors : í”„ë ˆì„ì›Œí¬ë¥¼ ì‚¬ìš©í•˜ëŠ”ê°€(Tensorflow ë˜ëŠ” PyTorch)ì— ë”°ë¼ input íƒ€ì…ì„ ë³€ê²½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "incorporate-guess",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': <tf.Tensor: shape=(3, 9), dtype=int32, numpy=\n",
      "array([[ 101, 8667,  146,  112,  182,  170, 1423, 5650,  102],\n",
      "       [ 101, 1262, 1330, 5650,  102,    0,    0,    0,    0],\n",
      "       [ 101, 1262, 1103, 1304, 1304, 1314, 1141,  102,    0]],\n",
      "      dtype=int32)>, 'token_type_ids': <tf.Tensor: shape=(3, 9), dtype=int32, numpy=\n",
      "array([[0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(3, 9), dtype=int32, numpy=\n",
      "array([[1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       [1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
      "       [1, 1, 1, 1, 1, 1, 1, 1, 0]], dtype=int32)>}\n"
     ]
    }
   ],
   "source": [
    "batch = tokenizer(batch_sentences, padding=True, truncation=True, return_tensors=\"tf\") \n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relative-cathedral",
   "metadata": {},
   "source": [
    "## 15-6. Huggingface transformers (3) Processor\n",
    "- ì•„ë˜ëŠ” Processor ì¤‘ Sequence Classification íƒœìŠ¤í¬ë¥¼ ìœ„í•œ ì¶”ìƒ í´ë˜ìŠ¤ì¸ DataProcessorì˜ ì½”ë“œ ì˜ˆì œ\n",
    "- processorëŠ” raw dataë¥¼ ê°€ê³µí•˜ì—¬ modelì— íƒœìš¸ ìˆ˜ ìˆëŠ” í˜•íƒœë¥¼ ë§Œë“¤ì–´ì£¼ëŠ” ì‘ì—…ì„ í•´ì£¼ëŠ” í´ë˜ìŠ¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "million-hebrew",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataProcessor:\n",
    "    \"\"\"sequence classificationì„ ìœ„í•´ dataë¥¼ ì²˜ë¦¬í•˜ëŠ” ê¸°ë³¸ processor\"\"\"\n",
    "\n",
    "    def get_example_from_tensor_dict(self, tensor_dict):\n",
    "        \"\"\"\n",
    "        tensor dictì—ì„œ exampleì„ ê°€ì ¸ì˜¤ëŠ” ë©”ì†Œë“œ\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def get_train_examples(self, data_dir):\n",
    "        \"\"\"train dataì—ì„œ InputExample í´ë˜ìŠ¤ë¥¼ ê°€ì§€ê³  ìˆëŠ” ê²ƒë“¤ì„ ëª¨ìœ¼ëŠ” ë©”ì†Œë“œ\"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def get_dev_examples(self, data_dir):\n",
    "        \"\"\"dev data(validation data)ì—ì„œ InputExample í´ë˜ìŠ¤ë¥¼ ê°€ì§€ê³  ìˆëŠ” ê²ƒë“¤ì„ ëª¨ìœ¼ëŠ” ë©”ì†Œë“œ\"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def get_test_examples(self, data_dir):\n",
    "        \"\"\"test dataì—ì„œ InputExample í´ë˜ìŠ¤ë¥¼ ê°€ì§€ê³  ìˆëŠ” ê²ƒë“¤ì„ ëª¨ìœ¼ëŠ” ë©”ì†Œë“œ\"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def get_labels(self):\n",
    "        \"\"\"data setì— ì‚¬ìš©ë˜ëŠ” ë¼ë²¨ë“¤ì„ ë¦¬í„´í•˜ëŠ” ë©”ì†Œë“œ\"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def tfds_map(self, example):\n",
    "        \"\"\"\n",
    "        tfds(tensorflow-datasets)ì—ì„œ ë¶ˆëŸ¬ì˜¨ ë°ì´í„°ë¥¼ DataProcessorì— ì•Œë§ê²Œ ê°€ê³µí•´ì£¼ëŠ” ë©”ì†Œë“œ\n",
    "        \"\"\"\n",
    "        if len(self.get_labels()) > 1:\n",
    "            example.label = self.get_labels()[int(example.label)]\n",
    "        return example\n",
    "\n",
    "    @classmethod\n",
    "    def _read_tsv(cls, input_file, quotechar=None):\n",
    "        \"\"\"tabìœ¼ë¡œ êµ¬ë¶„ëœ .tsvíŒŒì¼ì„ ì½ì–´ë“¤ì´ëŠ” í´ë˜ìŠ¤ ë©”ì†Œë“œ\"\"\"\n",
    "        with open(input_file, \"r\", encoding=\"utf-8-sig\") as f:\n",
    "            return list(csv.reader(f, delimiter=\"\\t\", quotechar=quotechar))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prospective-complement",
   "metadata": {},
   "source": [
    "## 15-7. Huggingface transformers (4) Config\n",
    "- hugging faceì˜ pretrained modelì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ê²Œ ë˜ë©´ ìë™ìœ¼ë¡œ configíŒŒì¼ì´ ë¡œë“œë˜ì–´ ëª…ì‹œí•  í•„ìš”ê°€ ì—†ì§€ë§Œ, <B> ì„¤ì •ì„ ë³€ê²½í•˜ê³  ì‹¶ê±°ë‚˜ ë‚˜ë§Œì˜ ëª¨ë¸ì„ í•™ìŠµì‹œí‚¬ ë•Œì—ëŠ” configíŒŒì¼ì„ ì§ì ‘ ë¶ˆëŸ¬ì™€ì•¼ í•©ë‹ˆë‹¤.</B>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "copyrighted-window",
   "metadata": {},
   "source": [
    "#### BertConfig ë°©ë²•1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cosmetic-watson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.models.bert.configuration_bert.BertConfig'>\n",
      "BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.2.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertConfig\n",
    "\n",
    "config = BertConfig.from_pretrained(\"bert-base-cased\")\n",
    "print(config.__class__)\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worldwide-valuation",
   "metadata": {},
   "source": [
    "#### AutoConfig ë°©ë²•2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "deluxe-adventure",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.models.bert.configuration_bert.BertConfig'>\n",
      "BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.2.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoConfig\n",
    "\n",
    "config = AutoConfig.from_pretrained(\"bert-base-cased\")\n",
    "print(config.__class__)\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liberal-columbia",
   "metadata": {},
   "source": [
    "####  ë§Œì•½ ëª¨ë¸ì„ ì´ë¯¸ ìƒì„±í–ˆë‹¤ë©´ model.configìœ¼ë¡œ ê°€ì ¸ì˜¬ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "diagnostic-teacher",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForPreTraining.\n",
      "\n",
      "All the layers of TFBertForPreTraining were initialized from the model checkpoint at bert-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForPreTraining for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.models.bert.configuration_bert.BertConfig'>\n",
      "BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.2.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = TFBertForPreTraining.from_pretrained('bert-base-cased')\n",
    "\n",
    "config = model.config\n",
    "print(config.__class__)\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aboriginal-catholic",
   "metadata": {},
   "source": [
    "## 15-8. Huggingface transformers (5) Trainer\n",
    "- trainerëŠ” ëª¨ë¸ì„ í•™ìŠµì‹œí‚¤ê¸° ìœ„í•œ í´ë˜ìŠ¤\n",
    "- tensorflowì˜ ê²½ìš° tf.keras.model APIë¥¼ ì´ìš©í•˜ì—¬ì„œë„ Huggingfaceë¥¼ í†µí•´ ë¶ˆëŸ¬ì˜¨ ëª¨ë¸ì„ í™œìš©í•´ í•™ìŠµì´ë‚˜ í…ŒìŠ¤íŠ¸ë¥¼ ì§„í–‰ ê°€ëŠ¥\n",
    "- TFTrainerë¥¼ ì´ìš©í•  ê²½ìš°ì—ëŠ” TrainingArguments ë¥¼ í†µí•´ Huggingface í”„ë ˆì„ì›Œí¬ì—ì„œ ì œê³µí•˜ëŠ” ê¸°ëŠ¥ë“¤ì„ í†µí•©ì ìœ¼ë¡œ ì»¤ìŠ¤í„°ë§ˆì´ì§•í•˜ì—¬ ëª¨ë¸ì„ í•™ìŠµì‹œí‚¬ ìˆ˜ ìˆë‹¤ëŠ” ì¥ì "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "seven-solid",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForPreTraining.\n",
      "\n",
      "All the layers of TFBertForPreTraining were initialized from the model checkpoint at bert-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForPreTraining for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7ff96fb42440>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7ff96fb42440>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Results=====\n",
      "TFBertForPreTrainingOutput(loss=None, prediction_logits=array([[[ -7.402721 ,  -7.362662 ,  -7.4500194, ...,  -6.195526 ,\n",
      "          -5.8948097,  -6.3672643],\n",
      "        [ -7.8287287,  -8.058227 ,  -7.8642054, ...,  -6.419407 ,\n",
      "          -6.3024297,  -6.7624664],\n",
      "        [-11.549938 , -11.551907 , -11.484703 , ...,  -8.114803 ,\n",
      "          -8.314196 ,  -9.444446 ],\n",
      "        ...,\n",
      "        [ -3.2660685,  -3.7416432,  -2.5797977, ...,  -4.0110044,\n",
      "          -2.4964385,  -3.0753932],\n",
      "        [-12.231962 , -12.027049 , -11.797822 , ...,  -8.838849 ,\n",
      "          -9.091648 , -10.497255 ],\n",
      "        [-10.639943 , -11.074335 , -11.036109 , ...,  -8.148462 ,\n",
      "          -9.585203 , -10.671506 ]]], dtype=float32), seq_relationship_logits=array([[ 1.6309197 , -0.71684647]], dtype=float32), hidden_states=None, attentions=None)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import TFAutoModelForPreTraining, AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')\n",
    "model = TFAutoModelForPreTraining.from_pretrained('bert-base-cased')\n",
    "\n",
    "sentence = \"Hello, This is test for bert TFmodel.\"\n",
    "\n",
    "input_ids = tf.constant(tokenizer.encode(sentence, add_special_tokens=True))[None, :]  # Batch size 1\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss)\n",
    "pred = model.predict(input_ids)\n",
    "\n",
    "print(\"=====Results=====\")\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "governing-guyana",
   "metadata": {},
   "source": [
    "#### TFTrainerë¥¼ ì‚¬ìš©í•  ê²½ìš°ì—ëŠ” í•™ìŠµì— í•„ìš”í•œ argumentsì„ TFTrainingArgumentsì„ í†µí•´ì„œ ì •ì˜í•´ ì£¼ì–´ì•¼ í•œë‹¤.\n",
    "- ì•„ë˜ëŠ” TFTrainerë¥¼ ì‚¬ìš©í•˜ì—¬ Huggingface ëª¨ë¸ì˜ í•™ìŠµì´ ì´ë£¨ì–´ì§€ëŠ” ì•„ì£¼ ê°„ë‹¨í•œ ì˜ˆì‹œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "broadband-virus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3201b0b7cff1422d96261c1a1d28c06c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8706d5ac1b4a4e6eafa9d3ac34560127",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/536M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2996dbc1ff86442cbd3c388e059d70ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aed512fb7be4da2893f656f6060d8d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from enum import Enum\n",
    "from typing import Dict, Optional\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from transformers import (\n",
    "    TFAutoModelForSequenceClassification,\n",
    "    TFTrainer,\n",
    "    TFTrainingArguments,\n",
    "    AutoConfig,\n",
    "    AutoTokenizer,\n",
    "    glue_convert_examples_to_features,\n",
    ")\n",
    "\n",
    "# TFTrainingArguments ì •ì˜\n",
    "training_args = TFTrainingArguments(\n",
    "    output_dir='./results',              # outputì´ ì €ì¥ë  ê²½ë¡œ\n",
    "    num_train_epochs=1,              # train ì‹œí‚¬ ì´ epochs\n",
    "    per_device_train_batch_size=16,  # ê° device ë‹¹ batch size\n",
    "    per_device_eval_batch_size=64,   # evaluation ì‹œì— batch size\n",
    "    warmup_steps=500,                # learning rate schedulerì— ë”°ë¥¸ warmup_step ì„¤ì •\n",
    "    weight_decay=0.01,                 # weight decay\n",
    "    logging_dir='./logs',                 # logê°€ ì €ì¥ë  ê²½ë¡œ\n",
    "    do_train=True,                        # train ìˆ˜í–‰ì—¬ë¶€\n",
    "    do_eval=True,                        # eval ìˆ˜í–‰ì—¬ë¶€\n",
    "    eval_steps=1000\n",
    ")\n",
    "\n",
    "# model, tokenizer ìƒì„±\n",
    "model_name_or_path = 'bert-base-uncased'\n",
    "with training_args.strategy.scope():    # training_argsê°€ ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” modelì˜ ë²”ìœ„ë¥¼ ì§€ì •\n",
    "    model = TFAutoModelForSequenceClassification.from_pretrained(\n",
    "            model_name_or_path,\n",
    "            from_pt=bool(\".bin\" in model_name_or_path),\n",
    "        )\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "        model_name_or_path,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grateful-quantum",
   "metadata": {},
   "source": [
    "#### ìœ„ì™€ ê°™ì´ Huggingface í”„ë ˆì„ì›Œí¬ êµ¬ì¡°ì— ë”°ë¼ Modelê³¼ Tokenizerë¥¼ ê°„ë‹¨íˆ ìƒì„±\n",
    "- model ìƒì„± ì‹œì— training_argsì˜ scope ì•ˆì—ì„œ ì§„í–‰í–ˆë‹¤ëŠ” ê²ƒì´ ëˆˆì— ë•ë‹ˆë‹¤.\n",
    "- <MARK> with êµ¬ë¬¸ì„ ìƒëµí•˜ë©´ TFTrainerì— ì „ë‹¬í•˜ê³ í”ˆ ì˜µì…˜ì´ ì œëŒ€ë¡œ ì „ë‹¬ë˜ì§€ ì•Šì•„ ê²°ê³¼ì ìœ¼ë¡œ ëª¨ë¸ì´ ì˜¤ë™ì‘í•˜ê²Œ ë˜ëŠ” ê²½ìš°ê°€ ìƒê¸¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤.</MARK>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "valued-gateway",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Load pre-computed DatasetInfo (eg: splits, num examples,...) from GCS: glue/mrpc/1.0.0\n",
      "INFO:absl:Load dataset info from /tmp/tmp8w85fevctfds\n",
      "INFO:absl:Field info.description from disk and from code do not match. Keeping the one from code.\n",
      "INFO:absl:Field info.config_name from disk and from code do not match. Keeping the one from code.\n",
      "INFO:absl:Field info.config_description from disk and from code do not match. Keeping the one from code.\n",
      "INFO:absl:Field info.citation from disk and from code do not match. Keeping the one from code.\n",
      "INFO:absl:Field info.location from disk and from code do not match. Keeping the one from code.\n",
      "INFO:absl:Field info.splits from disk and from code do not match. Keeping the one from code.\n",
      "INFO:absl:Field info.module_name from disk and from code do not match. Keeping the one from code.\n",
      "INFO:absl:Generating dataset glue (/aiffel/tensorflow_datasets/glue/mrpc/1.0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset 1.43 MiB (download: 1.43 MiB, generated: Unknown size, total: 1.43 MiB) to /aiffel/tensorflow_datasets/glue/mrpc/1.0.0...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf6637dbb9894cc8b9c175b5b6fcbae5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...: 0 url [00:00, ? url/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6188b183222e490cb2e001b221c3efeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Size...: 0 MiB [00:00, ? MiB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Downloading https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2Fmrpc_dev_ids.tsv?alt=media&token=ec5c0836-31d5-48f4-b431-7480817f1adc into /aiffel/tensorflow_datasets/downloads/fire.goog.com_v0_b_mtl-sent-repr.apps.com_o_2FjSIMlCiqs1QSmIykr4IRPnEHjPuGwAz5i40v8K9U0Z8.tsvalt=media&token=ec5c0836-31d5-48f4-b431-7480817f1adc.tmp.34222c4844794daaa4af743d41f5e08a...\n",
      "INFO:absl:Downloading https://dl.fbaipublicfiles.com/senteval/senteval_data/msr_paraphrase_test.txt into /aiffel/tensorflow_datasets/downloads/dl.fbaip.com_sente_sente_msr_parap_test0PdekMcyqYR-w4Rx_d7OTryq0J3RlYRn4rAMajy9Mak.txt.tmp.b522661f4a764383ba52771aa256bb97...\n",
      "INFO:absl:Downloading https://dl.fbaipublicfiles.com/senteval/senteval_data/msr_paraphrase_train.txt into /aiffel/tensorflow_datasets/downloads/dl.fbaip.com_sente_sente_msr_parap_trainfGxPZuQWGBti4Tbd1YNOwQr-OqxPejJ7gcp0Al6mlSk.txt.tmp.9038f932de4e4ecb9ab79a3f6f0be06f...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating splits...:   0%|          | 0/3 [00:00<?, ? splits/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train examples...:   0%|          | 0/3668 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling glue-train.tfrecord...:   0%|          | 0/3668 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Done writing glue-train.tfrecord. Number of examples: 3668 (shards: [3668])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation examples...:   0%|          | 0/408 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling glue-validation.tfrecord...:   0%|          | 0/408 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Done writing glue-validation.tfrecord. Number of examples: 408 (shards: [408])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test examples...:   0%|          | 0/1725 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling glue-test.tfrecord...:   0%|          | 0/1725 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Done writing glue-test.tfrecord. Number of examples: 1725 (shards: [1725])\n",
      "INFO:absl:Constructing tf.data.Dataset for split None, from /aiffel/tensorflow_datasets/glue/mrpc/1.0.0\n",
      "/opt/conda/lib/python3.7/site-packages/transformers/data/processors/glue.py:67: FutureWarning: This function will be removed from the library soon, preprocessing should be handled with the ğŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"function\"), FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/transformers/data/processors/glue.py:175: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ğŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset glue downloaded and prepared to /aiffel/tensorflow_datasets/glue/mrpc/1.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.45723017939814814}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ë°ì´í„°ì…‹ ìƒì„±\n",
    "ds, info = tfds.load('glue/mrpc', with_info=True)\n",
    "train_dataset = glue_convert_examples_to_features(ds['train'], tokenizer, 128, 'mrpc')\n",
    "train_dataset = train_dataset.apply(tf.data.experimental.assert_cardinality(info.splits['train'].num_examples))\n",
    "\n",
    "# TFTrainer ìƒì„±\n",
    "trainer = TFTrainer(\n",
    "    model=model,                          # í•™ìŠµì‹œí‚¬ model\n",
    "    args=training_args,                  # TFTrainingArgumentsì„ í†µí•´ ì„¤ì •í•œ arguments\n",
    "    train_dataset=train_dataset,   # training dataset\n",
    ")\n",
    "\n",
    "# í•™ìŠµ ì§„í–‰\n",
    "trainer.train()\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸\n",
    "test_dataset = glue_convert_examples_to_features(ds['test'], tokenizer, 128, 'mrpc')\n",
    "test_dataset = test_dataset.apply(tf.data.experimental.assert_cardinality(info.splits['test'].num_examples))\n",
    "trainer.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extended-dining",
   "metadata": {},
   "source": [
    "#### ì´í›„ ë°ì´í„°ì…‹ì„ ìƒì„±í•˜ì—¬, model, training_argsê³¼ í•¨ê»˜ TFTrainerì— ì „ë‹¬í•˜ëŠ” ê²ƒìœ¼ë¡œ í•™ìŠµì„ ìœ„í•œ ì¤€ë¹„ê°€ ë§ˆë¬´ë¦¬ë©ë‹ˆë‹¤. \n",
    "- ì´í›„ trainer.train()ì„ í˜¸ì¶œí•˜ë©´ ì‹¤ì œ í•™ìŠµì´ ì§„í–‰ë©ë‹ˆë‹¤"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

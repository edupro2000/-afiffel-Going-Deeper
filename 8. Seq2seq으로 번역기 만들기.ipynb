{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ruled-hungarian",
   "metadata": {},
   "source": [
    "#### 준비물 (터미널 셋팅)\n",
    "- mkdir -p ~/aiffel/s2s_translation\n",
    "- sudo apt -qq -y install fonts-nanum #글꼴 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "classical-yukon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "완료!\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "%config InlineBackend.figure_format = 'retina'\n",
    " \n",
    "import matplotlib.font_manager as fm\n",
    "fontpath = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'\n",
    "font = fm.FontProperties(fname=fontpath, size=9)\n",
    "plt.rc('font', family='NanumBarunGothic') \n",
    "mpl.font_manager._rebuild()\n",
    "\n",
    "print(\"완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "higher-biodiversity",
   "metadata": {},
   "source": [
    "### 1. 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "measured-canal",
   "metadata": {},
   "source": [
    "#### 1) 데이터 준비하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "arabic-receptor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "import io\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "passing-serial",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_zip = tf.keras.utils.get_file(\n",
    "    'spa-eng.zip',\n",
    "    origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip',\n",
    "    extract=True)\n",
    "\n",
    "path_to_file = os.path.dirname(path_to_zip)+\"/spa-eng/spa.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sealed-meaning",
   "metadata": {},
   "source": [
    "- tf.keras.utils.get_file(): URL로부터 데이터를 다운받고, 압축된 형식일 경우 해제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "corporate-watershed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Size: 118964\n",
      "Example:\n",
      ">> Go.\tVe.\n",
      ">> Wait.\tEsperen.\n",
      ">> Hug me.\tAbrázame.\n",
      ">> No way!\t¡Ni cagando!\n",
      ">> Call me.\tLlamame.\n"
     ]
    }
   ],
   "source": [
    "# 다운 받은 데이터 형태 확인\n",
    "\n",
    "with open(path_to_file, \"r\") as f:\n",
    "    raw = f.read().splitlines()\n",
    "\n",
    "print(\"Data Size:\", len(raw))\n",
    "print(\"Example:\")\n",
    "\n",
    "for sen in raw[0:100][::20]: print(\">>\", sen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "described-prediction",
   "metadata": {},
   "source": [
    "#### 2) 데이터 전처리: 정제하기\n",
    "- 데이터는 \\t 기호를 기준으로 영어와 스페인어가 병렬 쌍을 이루고 있다.  \\t 기호를 매개변수로 split() 함수를 호출하면 손쉽게 소스 문장과 타겟 문장을 분리가능\n",
    "- Decoder는 첫 입력으로 사용할 시작 토큰과 문장생성 종료를 알리는 끝 토큰이 반드시 필요하기 때문에 전처리 과정에서 문장의 시작 문자 <start>, 종료 문자 <end> 를 붙여주게된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "raised-drive",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝~\n"
     ]
    }
   ],
   "source": [
    "# 특수문자 제외\n",
    "\n",
    "def preprocess_sentence(sentence, s_token=False, e_token=False):\n",
    "    sentence = sentence.lower().strip()\n",
    "\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "    sentence = re.sub(r\"[^a-zA-Z?.!,]+\", \" \", sentence)\n",
    "\n",
    "    sentence = sentence.strip()\n",
    "\n",
    "    if s_token:\n",
    "        sentence = '<start> ' + sentence\n",
    "\n",
    "    if e_token:\n",
    "        sentence += ' <end>'\n",
    "    \n",
    "    return sentence\n",
    "\n",
    "print(\"슝~\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acute-adoption",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English: go away !\n",
      "Spanish: <start> salga de aqu ! <end>\n"
     ]
    }
   ],
   "source": [
    "# 상위 3만개 데이터 학습\n",
    "enc_corpus = []\n",
    "dec_corpus = []\n",
    "\n",
    "num_examples = 30000\n",
    "\n",
    "for pair in raw[:num_examples]:\n",
    "    eng, spa = pair.split(\"\\t\")\n",
    "\n",
    "    enc_corpus.append(preprocess_sentence(eng))\n",
    "    dec_corpus.append(preprocess_sentence(spa, s_token=True, e_token=True))\n",
    "\n",
    "print(\"English:\", enc_corpus[100])   # go away !\n",
    "print(\"Spanish:\", dec_corpus[100])   # <start> salga de aqu ! <end>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thousand-median",
   "metadata": {},
   "source": [
    "#### 데이터 전처리: 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "molecular-privacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정제된 텍스트를 아래처럼 토큰화 하고 텐서로 변환 (훈련데이터 80%, 검증데이터 20% 분리)\n",
    "\n",
    "def tokenize(corpus):\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "\n",
    "    tensor = tokenizer.texts_to_sequences(corpus)\n",
    "\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
    "\n",
    "    return tensor, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "elect-technical",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Vocab Size: 4931\n",
      "Spanish Vocab Size: 8893\n"
     ]
    }
   ],
   "source": [
    "# 토큰화하기\n",
    "enc_tensor, enc_tokenizer = tokenize(enc_corpus)\n",
    "dec_tensor, dec_tokenizer = tokenize(dec_corpus)\n",
    "\n",
    "# 훈련 데이터와 검증 데이터로 분리하기\n",
    "enc_train, enc_val, dec_train, dec_val = \\\n",
    "train_test_split(enc_tensor, dec_tensor, test_size=0.2) #split() 함수: 손쉽게 소스 문장과 타겟 문장을 분리\n",
    "\n",
    "print(\"English Vocab Size:\", len(enc_tokenizer.index_word))\n",
    "print(\"Spanish Vocab Size:\", len(dec_tokenizer.index_word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baking-strap",
   "metadata": {},
   "source": [
    "<mark>[1. 데이터 전처리 영역 학습 재정리]</mark>\n",
    "- 1) 데이터 준비 - tf.keras.utils.get_file(): URL로부터 데이터를 다운받고, 압축된 형식일 경우 해제\n",
    "- 2) 데이터 전처리: 정제하기\n",
    "    - \\t 기호를 매개변수로 split() 함수를 호출하면 손쉽게 소스 문장과 타겟 문장을 분리가능\n",
    "    - Decoder는 첫 입력으로 사용할 시작 토큰과 문장생성 종료를 알리는 끝 토큰이 반드시 필요\n",
    "- 3) 데이터 토큰화\n",
    "   - 토큰화후 텐서로 변환, 훈련데이터, 훈련 데이터와 검증 데이터로 분리하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "characteristic-horror",
   "metadata": {},
   "source": [
    "### 2. 모델설계\n",
    "- Encoder는 모든 Time-Step의 Hidden State(=기억)를 출력\n",
    "- Decoder는 Encoder의 출력과 Decoder의 t-1 Step의 Hidden State로 Attention을 취하여 t Step의 Hidden State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "surprising-pitch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝~\n"
     ]
    }
   ],
   "source": [
    "# Attention은 Bahdanau을 사용 *7번 노드 참고\n",
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.w_dec = tf.keras.layers.Dense(units)\n",
    "        self.w_enc = tf.keras.layers.Dense(units)\n",
    "        self.w_com = tf.keras.layers.Dense(1)\n",
    "    \n",
    "    def call(self, h_enc, h_dec):\n",
    "        # h_enc shape: [batch x length x units]\n",
    "        # h_dec shape: [batch x units]\n",
    "\n",
    "        h_enc = self.w_enc(h_enc)   \n",
    "        h_dec = tf.expand_dims(h_dec, 1)\n",
    "        h_dec = self.w_dec(h_dec)  #인코더의 실제 히든디코더를 한번 더 확인하도록\n",
    "\n",
    "        score = self.w_com(tf.nn.tanh(h_dec + h_enc))  #탄젠트\n",
    "        \n",
    "        attn = tf.nn.softmax(score, axis=1) #소프트맥스\n",
    "\n",
    "        context_vec = attn * h_enc   #컨텍스벡터 어텐션가중치 *컨벡스트백터(히든디코더)\n",
    "        context_vec = tf.reduce_sum(context_vec, axis=1) # 가중치 다 더해주기\n",
    "\n",
    "        return context_vec, attn\n",
    "\n",
    "print(\"슝~\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "promotional-ceramic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder 클래스와 설계 \n",
    "\n",
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(enc_units,\n",
    "                                       return_sequences=True)\n",
    "        \n",
    "    def call(self, x):\n",
    "        out = self.embedding(x)\n",
    "        out = self.gru(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "funded-stations",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder 클래스를 설계\n",
    "    \n",
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(dec_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True)\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "    def call(self, x, h_dec, enc_out):\n",
    "        context_vec, attn = self.attention(enc_out, h_dec)\n",
    "\n",
    "        out = self.embedding(x)\n",
    "        out = tf.concat([tf.expand_dims(context_vec, 1), out], axis=-1)\n",
    "        \n",
    "        out, h_dec = self.gru(out)\n",
    "        out = tf.reshape(out, (-1, out.shape[2]))\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out, h_dec, attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "military-trace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder Output: (64, 30, 1024)\n",
      "Decoder Output: (64, 8894)\n",
      "Decoder Hidden State: (64, 1024)\n",
      "Attention: (64, 30, 1)\n"
     ]
    }
   ],
   "source": [
    "# 코드를 실행하세요.\n",
    "\n",
    "BATCH_SIZE     = 64\n",
    "SRC_VOCAB_SIZE = len(enc_tokenizer.index_word) + 1\n",
    "TGT_VOCAB_SIZE = len(dec_tokenizer.index_word) + 1\n",
    "\n",
    "units         = 1024\n",
    "embedding_dim = 512\n",
    "\n",
    "encoder = Encoder(SRC_VOCAB_SIZE, embedding_dim, units)\n",
    "decoder = Decoder(TGT_VOCAB_SIZE, embedding_dim, units)\n",
    "\n",
    "# sample input\n",
    "sequence_len = 30\n",
    "\n",
    "sample_enc = tf.random.uniform((BATCH_SIZE, sequence_len))\n",
    "sample_output = encoder(sample_enc)\n",
    "\n",
    "print ('Encoder Output:', sample_output.shape)\n",
    "\n",
    "sample_state = tf.random.uniform((BATCH_SIZE, units))\n",
    "\n",
    "sample_logits, h_dec, attn = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
    "                                     sample_state, sample_output)\n",
    "\n",
    "print ('Decoder Output:', sample_logits.shape)\n",
    "print ('Decoder Hidden State:', h_dec.shape)\n",
    "print ('Attention:', attn.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "important-handling",
   "metadata": {},
   "source": [
    "[재 복습 - Bahdanau_Attention] \n",
    "- = 이름 : concat\n",
    "- 현재 타임 스텝의 디코더 Hidden State Vector $s_t$ 를 구하기 위해서 현재 타임 스텝의 Context Vector  $c_t$  및 이전 타임 스텝의 Hidden State Vector  $s_t-1$, 그리고 현재 타임 스텝의 입력으로 들어온  $y_t-1$ 이 사용되게 된다. 이 때  Context Vector $c_t$는 $s_t-1$과 인코더 Hidden State Matrix 를 이용한 Attention 메커니즘의 결과가 된다. \n",
    "\n",
    "![Bahdanau_Attention](https://user-images.githubusercontent.com/70866993/137129301-28753f44-751e-4658-8210-f9330ca0c9d0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "married-decision",
   "metadata": {},
   "source": [
    "<mark> 2. 모델 설계 영역 학습 재정리</mark>\n",
    "- 1) 어텐션 선택\n",
    "- 2) Encoder 클래스와 설계 \n",
    "- 3) Decoder 클래스를 설계"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bulgarian-personality",
   "metadata": {},
   "source": [
    "### 3. 훈련하기\n",
    "- Encoder-Decoder 구조의 경우 입출력이 단순하지 않아 학습 과정을 직접 정의, fit()으로 학습시키지 않음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "approximate-broadway",
   "metadata": {},
   "source": [
    "#### Optimizer & Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "automatic-salmon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝~\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy( \n",
    "    from_logits=True, reduction='none')  \n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss = loss_object(real, pred)\n",
    "    \n",
    "    mask = tf.cast(mask, dtype=loss.dtype)\n",
    "    loss *= mask # 패딩처리, <PAD> 토큰을 찾아내어 그 부분에 대한 Loss는 구하지 않도록 하는 역할\n",
    "    \n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "print(\"슝~\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "green-pavilion",
   "metadata": {},
   "source": [
    "- SparseCategoricalCrossentropy() 함수 :  모델이 출력한 확률 분포와 (One-hot이 아닌) 정수 인덱스 답안을 비교해 Cross Entropy값을 구해준다.\n",
    "- loss *= mask # 패딩처리, <PAD> 토큰을 찾아내어 그 부분에 대한 Loss는 구하지 않도록 하는 역할"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developed-antique",
   "metadata": {},
   "source": [
    "### 4. train_step 구현하기\n",
    "- train_step() : 학습에 필요한 것을 모두 가져가 Loss를 계산한 후 반환하는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "objective-steering",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝~\n"
     ]
    }
   ],
   "source": [
    "@tf.function  # 훈련 외적인 텐서플로우 연산을  GPU에서 동작하게 해 훈련을 가속할 수 있도록 도와wnsek.\n",
    "def train_step(src, tgt, encoder, decoder, optimizer, dec_tok):\n",
    "    bsz = src.shape[0]\n",
    "    loss = 0\n",
    "\n",
    "    with tf.GradientTape() as tape: #tf.GradientTape() : 학습하며 발생한 모든 연산을 기록하는 테이프\n",
    "        enc_out = encoder(src)\n",
    "        h_dec = enc_out[:, -1] # Encoder에 소스 문장을 전달해 컨텍스트 벡터인 enc_out 생성,(Encoder의 Final State 정의)\n",
    "        \n",
    "        dec_src = tf.expand_dims([dec_tok.word_index['<start>']] * bsz, 1) # Decoder에 입력으로 전달할 <start> 토큰 문장 생성\n",
    "\n",
    "        for t in range(1, tgt.shape[1]):\n",
    "            pred, h_dec, _ = decoder(dec_src, h_dec, enc_out) #<start> 문장과 enc_out, Hidden State를 기반으로 다음 단어(t=1)를 예측\n",
    "\n",
    "            loss += loss_function(tgt[:, t], pred)# 예측된 단어와 정답 간의 Loss를 구한 후, t=1의 정답 단어를 다음 입력으로 사용 (예측 단어 X)\n",
    "            dec_src = tf.expand_dims(tgt[:, t], 1)\n",
    "        \n",
    "    batch_loss = (loss / int(tgt.shape[1]))\n",
    "\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "    \n",
    "    return batch_loss\n",
    "\n",
    "print(\"슝~\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "british-sword",
   "metadata": {},
   "source": [
    "### 5. 훈련 시작하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "played-synthetic",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  1: 100%|██████████| 375/375 [04:00<00:00,  1.56it/s, Loss 1.3497]\n",
      "Epoch  2: 100%|██████████| 375/375 [03:39<00:00,  1.71it/s, Loss 0.8820]\n",
      "Epoch  3: 100%|██████████| 375/375 [03:41<00:00,  1.69it/s, Loss 0.6198]\n",
      "Epoch  4: 100%|██████████| 375/375 [03:40<00:00,  1.70it/s, Loss 0.4441]\n",
      "Epoch  5:  93%|█████████▎| 349/375 [03:24<00:15,  1.64it/s, Loss 0.3274]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm    # tqdm : 훈련의 진행 과정을 한눈에 볼 수 있게 해주는 라이브러리\n",
    "import random\n",
    "\n",
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "    \n",
    "    idx_list = list(range(0, enc_train.shape[0], BATCH_SIZE))  #각 배치의 시작 인덱스를 idx_list 배열에 저장\n",
    "    random.shuffle(idx_list)  #랜덤 인덱스 섞기\n",
    "    t = tqdm(idx_list)    # tqdm\n",
    "\n",
    "    for (batch, idx) in enumerate(t):\n",
    "        batch_loss = train_step(enc_train[idx:idx+BATCH_SIZE], #train_step 하습에 필요한것을 모두 가져가 Loss 계산후 반환\n",
    "                                dec_train[idx:idx+BATCH_SIZE],\n",
    "                                encoder,\n",
    "                                decoder,\n",
    "                                optimizer,\n",
    "                                dec_tokenizer)\n",
    "    \n",
    "        total_loss += batch_loss\n",
    "        \n",
    "        t.set_description_str('Epoch %2d' % (epoch + 1))    # tqdm\n",
    "        t.set_postfix_str('Loss %.4f' % (total_loss.numpy() / (batch + 1)))    # tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guided-cinema",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define eval_step() 정의하기\n",
    "\n",
    "@tf.function\n",
    "def eval_step(src, tgt, encoder, decoder, dec_tok):\n",
    "    bsz = src.shape[0]\n",
    "    loss = 0\n",
    "\n",
    "    enc_out = encoder(src)\n",
    "\n",
    "    h_dec = enc_out[:, -1]\n",
    "    \n",
    "    dec_src = tf.expand_dims([dec_tok.word_index['<start>']] * bsz, 1)\n",
    "\n",
    "    for t in range(1, tgt.shape[1]):\n",
    "        pred, h_dec, _ = decoder(dec_src, h_dec, enc_out)\n",
    "\n",
    "        loss += loss_function(tgt[:, t], pred)\n",
    "        dec_src = tf.expand_dims(tgt[:, t], 1)\n",
    "        \n",
    "    batch_loss = (loss / int(tgt.shape[1]))\n",
    "    \n",
    "    return batch_loss\n",
    "\n",
    "\n",
    "# 5. 훈련시작하기와 동일(total_loss, test_loss)\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    total_loss = 0   # total_loss\n",
    "    \n",
    "    idx_list = list(range(0, enc_train.shape[0], BATCH_SIZE))\n",
    "    random.shuffle(idx_list)\n",
    "    t = tqdm(idx_list)\n",
    "\n",
    "    for (batch, idx) in enumerate(t):\n",
    "        batch_loss = train_step(enc_train[idx:idx+BATCH_SIZE],\n",
    "                                dec_train[idx:idx+BATCH_SIZE],\n",
    "                                encoder,\n",
    "                                decoder,\n",
    "                                optimizer,\n",
    "                                dec_tokenizer)\n",
    "    \n",
    "        total_loss += batch_loss  #total_loss\n",
    "        \n",
    "        t.set_description_str('Epoch %2d' % (epoch + 1))\n",
    "        t.set_postfix_str('Loss %.4f' % (total_loss.numpy() / (batch + 1)))\n",
    "    \n",
    "    test_loss = 0  #test_loss\n",
    "    \n",
    "    idx_list = list(range(0, enc_val.shape[0], BATCH_SIZE))\n",
    "    random.shuffle(idx_list)\n",
    "    t = tqdm(idx_list)\n",
    "\n",
    "    for (test_batch, idx) in enumerate(t):\n",
    "        test_batch_loss = eval_step(enc_val[idx:idx+BATCH_SIZE],\n",
    "                                    dec_val[idx:idx+BATCH_SIZE],\n",
    "                                    encoder,\n",
    "                                    decoder,\n",
    "                                    dec_tokenizer)\n",
    "    \n",
    "        test_loss += test_batch_loss   #test_loss\n",
    "\n",
    "        t.set_description_str('Test Epoch %2d' % (epoch + 1))\n",
    "        t.set_postfix_str('Test Loss %.4f' % (test_loss.numpy() / (test_batch + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frozen-provision",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 번역 성능 평가하기,  Attention Map을 시각화\n",
    "\n",
    "def evaluate(sentence, encoder, decoder):\n",
    "    attention = np.zeros((dec_train.shape[-1], enc_train.shape[-1]))\n",
    "    \n",
    "    sentence = preprocess_sentence(sentence)\n",
    "    inputs = enc_tokenizer.texts_to_sequences([sentence.split()])\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences(inputs,\n",
    "                                                           maxlen=enc_train.shape[-1],\n",
    "                                                           padding='post')\n",
    "\n",
    "    result = ''\n",
    "\n",
    "    enc_out = encoder(inputs)\n",
    "\n",
    "    dec_hidden = enc_out[:, -1]\n",
    "    dec_input = tf.expand_dims([dec_tokenizer.word_index['<start>']], 0)\n",
    "\n",
    "    for t in range(dec_train.shape[-1]):\n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
    "                                                             dec_hidden,\n",
    "                                                             enc_out)\n",
    "\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        attention[t] = attention_weights.numpy()\n",
    "\n",
    "        predicted_id = \\\n",
    "        tf.argmax(tf.math.softmax(predictions, axis=-1)[0]).numpy()\n",
    "\n",
    "        result += dec_tokenizer.index_word[predicted_id] + ' '\n",
    "\n",
    "        if dec_tokenizer.index_word[predicted_id] == '<end>':\n",
    "            return result, sentence, attention\n",
    "\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    return result, sentence, attention\n",
    "\n",
    "\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "    fontdict = {'fontsize': 14}\n",
    "\n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def translate(sentence, encoder, decoder):\n",
    "    result, sentence, attention = evaluate(sentence, encoder, decoder)\n",
    "\n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "    \n",
    "    attention = attention[:len(result.split()), :len(sentence.split())]\n",
    "    plot_attention(attention, sentence.split(), result.split(' '))\n",
    "\n",
    "\n",
    "translate(\"Can I have some coffee?\", encoder, decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demanding-cartridge",
   "metadata": {},
   "source": [
    "## 프로젝트 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "phantom-restaurant",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranking-third",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unavailable-difficulty",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extreme-illustration",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affecting-roads",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moderate-chile",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "married-found",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earned-aruba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "speaking-indianapolis",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mounted-background",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enclosed-centre",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chronic-religious",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disturbed-rugby",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "present-electron",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earlier-operator",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accepted-electronics",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composite-pennsylvania",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "russian-politics",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "purple-beast",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
